# ---
# jupyter:
#   granta:
#     clean_database: true
#   jupytext:
#     notebook_metadata_filter: granta
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.14.1
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# # Creating an Excel import job

# An Excel import job is used to import data from a properly formatted Excel spreadsheet.
#
# This example shows the steps required to create an Excel import job request, submit it to the job
# queue, and interact with the resulting Excel import job object returned by the server.
#
# The details of how to create a properly-formatted Excel import template are outside the scope of
# this example. Consult the Granta MI documentation or your ACE representative for information on
# the use of Excel for importing data into Granta MI.

# ## Connecting to Granta MI

# Import the ``Connection`` class and create the connection. See the
# [Getting started](0_Getting_started.ipynb) example for more detail.

# + tags=[]
from ansys.grantami.jobqueue import Connection

server_url = "http://my_grantami_server/mi_servicelayer"
client = Connection(server_url).with_credentials("user_name", "password").connect()
# -

# ## Create an Excel import job request object

# The first step in importing an Excel file with the job queue is to create an
# ``ExcelImportJobRequest`` object. When creating this object, specify the name of the job and the
# file(s) to be imported. You can also specify an optional description and the scheduled execution
# date, if the import should be deferred until that date and time.
#
# Different job types require different input files. For example, an Excel import can use a
# 'template' and one or more 'data' files, or a single 'combined' file. Any additional files
# to be imported as file attributes should be specified as 'attachment' files. These can be provided
# as relative or absolute paths or as `pathlib.Path` objects.

# +
from ansys.grantami.jobqueue import ExcelImportJobRequest

separate_excel_import_request = ExcelImportJobRequest(
    name="Excel Import (separate template and data files)",
    description="An example excel import job",
    data_files=["data_file_1.xlsx", "data_file_2.xlsx"],
    template_files=["import_template.xlsx"],
)
separate_excel_import_request
# -

# ## Submit the job to the server
# Next, submit the jobs to the server. There are two ways to submit the job:
#
# * ``create_job()``: Submit the job request to the server and immediately return an
#   ``AsyncJob`` object in the 'pending' state.
# * ``create_job_and_wait()``: Submit the job request to the server and block until the job
#    either completes or fails. Return an ``AsyncJob`` object in the 'succeeded' or 'failed' state.
#
# This example uses the ``create_job_and_wait()`` method. See
# [Scheduling and modifying jobs](4_Scheduling_and_modifying_jobs.ipynb) for an example that shows
# how to create and submit a job that runs asynchronously.

# +
completed_job = client.create_job_and_wait(separate_excel_import_request)
# -

# ## Access output files
# Finally, access the results of the job. Import jobs typically create log files, but the exact type
# of files generated varies based on the type of import template. In this case, the files are all
# plain text.

# Access the list of files generated by the job with the ``output_file_names`` property. This
# returns a list of file names.

completed_job.output_file_names

# In general, an Excel import job will return two files:
#
# 1. \<job name>.log: the log file of the import operation on the server
# 2. summary.json: a data file which summarizes the number of records impacted by the import
#    job

# The following cell shows accessing the content of the log file as ``bytes`` using the
# ``AsyncJob.get_file_content`` method.

# +
log_file_name = next(name for name in completed_job.output_file_names if "log" in name)
log_file_content = completed_job.get_file_content(log_file_name)
log_file_string = log_file_content.decode("utf-8")
print(f"{log_file_name} (first 200 characters):")
print(f"{log_file_string[:500]}...")
# -

# The following cell shows downloading the import summary file to disk with the
# ``AsyncJob.download_file`` method.

# +
summary_file_name = next(name for name in completed_job.output_file_names if name == "summary.json")
output_path = f"./{summary_file_name}"
completed_job.download_file(summary_file_name, output_path)
f"{summary_file_name} saved to disk"
# -
